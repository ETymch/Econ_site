uncertainty = c()
for (i in 1:(length(beir_new)-30)){
uncertainty[i] = sd(beir_new[i:(i+30)])
}
beir_un <- beir_new[31:length(beir_new)] - uncertainty
beir_un <- c(beir_new[1:30], beir_new[31:length(beir_new)] - uncertainty)
ie_new <- data.frame(date = df_all_1$Date,
ie_new = beir_new + lp_new,
ie_new_u = beir_un + lp_new
)
all <- merge(ie_old, ie_new, by = 'date', all = T)
ie_new %>%
melt(id = 'date') %>%
ggplot(aes(x = date, y = value, color = variable)) +
geom_line() +
geom_vline(xintercept = as.Date('2022-02-28'), linewidth = 1.5, alpha = 0.1) +
theme_minimal()
write.csv(ie_new, 'ie_daily_new_30_01_24.csv')
########################################################
# Модель с меняющимся трендом и экзогенными старыми ИО #
########################################################
# Новые ИО, которые нужно спрогнозировать
ie_y <-
all %>%
filter(date <= '2023-01-23') %>%
select(ie_new_u) %>%
t()
ie_c <- all %>%
filter(date <= '2023-01-23') %>%
select(ie_old)
ie_c <-
ie_c$ie_old %>%
diff()
ie_c <- c(0, ie_c) %>%
t()
# Модель со старыми ожиданиями как экзогенной переменной и меняющимся трендом.
Z = matrix(c(1,0), 1, 2)
B = matrix(c(1, 0, 1, 1), 2, 2)
A = matrix(0)
C <- matrix(list(0),2,1)
C[1,1] <- 'c'
c <- ie_c
U = matrix(0, 2, 1)
R = matrix('r')
Q = matrix(c('q1', 0, 0, 'q2'), 2, 2) # вместо q и p подставим малые значения
x0 = matrix(c(5.45, 0.0), 2, 1) # новые начальные условия
model_3 <- MARSS(ie_y, model = list(Z = Z, B = B, A = A, c = c, C = C, U = U, R = R, Q = Q, x0 = x0),
control = list(maxit = 600)
)
df <- read.csv("mfdexport_1day_01082011_04032024.csv", sep = ';')
df$Date <- as.Date(as.character(df$X.DATE.), format = "%Y%m%d")
df_26211 <- df %>% filter(X.TICKER. == 'ОФЗ 26211')%>%
select(Date, X.CLOSE.)
colnames(df_26211) <- c('Date', 'Price')
df_26211$Coupon = 7.0
df_26211 <- df_26211 %>% mutate(Yield = Coupon * 100 / Price)
df_26211$Bond <- 'ofz_26211'
df_26215 <- df %>% filter(X.TICKER. == 'ОФЗ 26215') %>%
select(Date, X.CLOSE.)
colnames(df_26215) <- c('Date', 'Price')
df_26215$Coupon = 7.0
df_26215 <- df_26215 %>% mutate(Yield = Coupon * 100 / Price)
df_26215$Bond <- 'ofz_26215'
df_26219 <- df %>% filter(X.TICKER. == 'ОФЗ 26219') %>%
select(Date, X.CLOSE.)
colnames(df_26219) <- c('Date', 'Price')
df_26219$Coupon = 7.75
df_26219 <- df_26219 %>% mutate(Yield = Coupon * 100 / Price)
df_26219$Bond <- 'ofz_26219'
df_52001 <- df %>% filter(X.TICKER. == 'ОФЗ 52001') %>%
select(Date, X.CLOSE.)
colnames(df_52001) <- c('Date', 'Price')
df_52001$Coupon = 2.5
df_52001 <- df_52001 %>% mutate(Yield = Coupon * 100 / Price)
df_52001$Bond <- 'ofz_52001'
df_all <- merge(df_26211, df_26215, by = 'Date') %>% merge(df_26219, by = 'Date') %>% merge(df_52001, by = 'Date')
beir_old <- df_all[,8] - df_all[,16]
lp_old <- df_all[,12] - df_all[,4]
ie_old <- data.frame(date = df_all$Date,
ie_old = beir_old + lp_old
)
ie_old_ts <- xts(ie_old$ie_old, order.by = ie_old$date)
#############################################################################
# New 52002 version of IE ###################################################
# We now use adjusted bond Yields to calcylate IE, see MOEX methodology #####
# https://fs.moex.com/files/6908/ ###########################################
#############################################################################
df_26224 <- df %>% filter(X.TICKER. == 'ОФЗ 26224')%>%
select(Date, X.CLOSE.)
colnames(df_26224) <- c('Date', 'Price')
df_26224$Coupon = 6.9
df_26224 <- df_26224 %>% mutate(Yield = Coupon * 100 / Price)
df_26224$Bond <- 'ofz_26224'
df_26224$Yield_c <- df_26224$Yield + (100 - df_26224$Price) / (as.numeric(rep(as.Date('2029-05-23'), length(df_26224$Date)) - df_26224$Date) / 365)
df_26232 <- df %>% filter(X.TICKER. == 'ОФЗ 26232') %>%
select(Date, X.CLOSE.)
colnames(df_26232) <- c('Date', 'Price')
df_26232$Coupon = 6.0
df_26232 <- df_26232 %>% mutate(Yield = Coupon * 100 / Price)
df_26232$Bond <- 'ofz_26232'
df_26232$Yield_c <- df_26232$Yield + (100 - df_26232$Price) / (as.numeric(rep(as.Date('2027-10-06'), length(df_26232$Date)) - df_26232$Date) / 365)
df_26235 <- df %>% filter(X.TICKER. == 'ОФЗ 26235') %>%
select(Date, X.CLOSE.)
colnames(df_26235) <- c('Date', 'Price')
df_26235$Coupon = 5.9
df_26235 <- df_26235 %>% mutate(Yield = Coupon * 100 / Price)
df_26235$Bond <- 'ofz_26235'
df_26235$Yield_c <- df_26235$Yield + (100 - df_26235$Price) / (as.numeric(rep(as.Date('2031-03-12'), length(df_26235$Date)) - df_26235$Date) / 365)
df_52002 <- df %>% filter(X.TICKER. == 'ОФЗ 52002') %>%
select(Date, X.CLOSE.)
colnames(df_52002) <- c('Date', 'Price')
df_52002$Coupon = 2.5
df_52002 <- df_52002 %>% mutate(Yield = Coupon * 100 / Price)
df_52002$Bond <- 'ofz_52002'
df_52002$Yield_c <- df_52002$Yield + (100 - df_52002$Price) / (as.numeric(rep(as.Date('2028-02-02'), length(df_52002$Date)) - df_52002$Date) / 365)
df_all_1 <- merge(df_26224, df_26232, by = 'Date') %>% merge(df_26235, by = 'Date') %>% merge(df_52002, by = 'Date')
beir_new <- df_all_1[,11] - df_all_1[,21]
lp_new <- df_all_1[,16] - df_all_1[,6]
beir_new <- xts(beir_new, order.by = df_all_1$Date)
beir_new %>% plot(ylim = c(2.5, 10.5))
uncertainty = c()
for (i in 1:(length(beir_new)-30)){
uncertainty[i] = sd(beir_new[i:(i+30)])
}
beir_un <- beir_new[31:length(beir_new)] - uncertainty
beir_un <- c(beir_new[1:30], beir_new[31:length(beir_new)] - uncertainty)
ie_new <- data.frame(date = df_all_1$Date,
ie_new = beir_new + lp_new,
ie_new_u = beir_un + lp_new
)
all <- merge(ie_old, ie_new, by = 'date', all = T)
ie_new %>%
melt(id = 'date') %>%
ggplot(aes(x = date, y = value, color = variable)) +
geom_line() +
geom_vline(xintercept = as.Date('2022-02-28'), linewidth = 1.5, alpha = 0.1) +
theme_minimal()
write.csv(ie_new, 'ie_daily_new_04_03_24.csv')
ie_y <-
all %>%
filter(date <= '2023-01-23') %>%
select(ie_new_u) %>%
t()
ie_c <- all %>%
filter(date <= '2023-01-23') %>%
select(ie_old)
ie_c <-
ie_c$ie_old %>%
diff()
ie_c <- c(0, ie_c) %>%
t()
# Модель со старыми ожиданиями как экзогенной переменной и меняющимся трендом.
Z = matrix(c(1,0), 1, 2)
B = matrix(c(1, 0, 1, 1), 2, 2)
A = matrix(0)
C <- matrix(list(0),2,1)
C[1,1] <- 'c'
c <- ie_c
U = matrix(0, 2, 1)
R = matrix('r')
Q = matrix(c('q1', 0, 0, 'q2'), 2, 2) # вместо q и p подставим малые значения
x0 = matrix(c(5.45, 0.0), 2, 1) # новые начальные условия
model_3 <- MARSS(ie_y, model = list(Z = Z, B = B, A = A, c = c, C = C, U = U, R = R, Q = Q, x0 = x0),
control = list(maxit = 600)
)
all$ie_new_u[1:length(model_3$states[1,])] <- model_3$states[1,] %>% c()
ie_old_lm <- read.csv('ie_lm.csv')
ie_old_filters <- read.csv('ie_filters.csv')
date = all$date[1:length(ie_old_lm$V1)]
ie_new_u <- all$ie_new_u
tibble(date,
ie_old_lm = ie_old_lm$V1,
ie_old_filters = ie_old_filters$V1,
ie_new_u = ie_new_u[1:length(date)]
)
all %>%
write.csv('ie_daily_04_03_2024.csv')
ie_new <- read.csv('ie_daily_17_10_2023.csv')
ie_new <- xts(ie_new$ie_new_u, order.by = as.Date(ie_new$date)) %>%
apply.monthly(mean) %>%
fortify.zoo(names = c('date', 'ie_new')) %>%
as.tibble() %>%
mutate(date = floor_date(date, 'month')) %>%
rename('ie_new' = '.')
ie_bor <- read.csv('ie_Bank_of_Russia.csv', header = T, dec = ',', sep = ';') %>%
select(date, expected) %>%
mutate(date = as.Date(date, tryFormats = c("%d.%m.%Y"))
)
data_ie <- merge(ie_new, ie_bor, by = 'date', all = T)
# Part 1: Model for IE_BOR
ie_y <- data_ie %>%
filter(date >= '2016-08-01') %>%
dplyr::select(expected) %>%
t()
ie_c <- data_ie %>%
filter(date >= '2016-07-01')
ie_c <- ie_c$ie_new %>%
diff() %>%
t()
# Модель с нашими ожиданиями как экзогенной переменной и меняющимся трендом.
Z = matrix(c(1,0), 1, 2)
B = matrix(c(1, 0, 1, 1), 2, 2)
A = matrix(0)
C <- matrix(list(0),2,1)
C[1,1] <- 'c'
c <- ie_c
U = matrix(0, 2, 1)
R = matrix('r')
Q = 'unconstrained'
#Q = matrix(c('q1', 0, 0, 'q2'), 2, 2) # вместо q и p подставим малые значения
x0 = matrix(c(10.45, 0.0), 2, 1) # новые начальные условия
model_bor <- MARSS(ie_y, model = list(Z = Z, B = B, A = A, c = c, C = C, U = U, R = R, Q = Q, x0 = x0),
control = list(maxit = 300)
)
data_ie$expected_m[which(data_ie$date >= '2016-08-01')] <- model_bor$states[1,] %>%
round(1)
data_ie$expected_m[which(data_ie$date < '2016-08-01')] <- data_ie$expected[which(data_ie$date < '2016-08-01')]
data_ie %>%
select(date, expected, expected_m) %>%
pivot_longer(expected:expected_m) %>%
ggplot(aes(x = date, y = value, color = name)) +
geom_point() +
geom_line() +
theme_minimal()
indices <- which(data_ie$expected %>% is.na)
data_ie$expected[indices] <- data_ie$expected_m[indices]
data_ie %>%
select(date, expected) %>%
writexl::write_xlsx('ie_bor_m_2024.xlsx')
ie_y <- data_ie %>%
dplyr::select(ie_new) %>%
t()
ie_c <-
data_ie$expected %>%
diff()
ie_c <- c(0, ie_c) %>%
t()
# Модель с нашими ожиданиями как экзогенной переменной и меняющимся трендом.
Z = matrix(c(1,0), 1, 2)
B = matrix(c(1, 0, 1, 1), 2, 2)
A = matrix(0)
C <- matrix(list(0),2,1)
C[1,1] <- 'c'
c <- ie_c
U = matrix(0, 2, 1)
R = matrix('r')
Q = matrix(c('q1', 0, 0, 'q2'), 2, 2) # вместо q и p подставим малые значения
x0 = matrix(c(5.0, 0.1), 2, 1) # новые начальные условия
model_ie_m <- MARSS(ie_y, model = list(Z = Z, B = B, A = A, c = c, C = C, U = U, R = R, Q = Q, x0 = x0),
control = list(maxit = 300)
)
tibble(date = data_ie$date,
ie_mod = model_ie_m$states[1,],
) %>%
write.csv('ie_monthly_04_03_24.csv')
df_fin <- tibble(date = data_ie$date,
ie_mod = model_ie_m$states[1,],
)
ie_u <- all %>%
mutate(date = floor_date(date, 'month')) %>%
group_by(date) %>%
summarize(ie_mod = mean(ie_new_u))
to_append <- setdiff(ie_u$date, df_fin$date) %>% length()
df_fin <-
df_fin %>%
rbind(ie_u[(length(ie_u$date)-to_append+1):length(ie_u$date),])
df_fin %>%
write.csv('ie_monthly_04_03_24.csv')
library(tidyverse)
library(ggridges)
library(showtext)
library(sysfonts)
library(rcartocolor)
library(hrbrthemes)
showtext_auto()
font_add(family = 'HSE Sans',
regular = "HSESans-Regular.otf",
bold = 'HSESans-Bold.otf',
italic = 'HSESans-Italic.otf',
bolditalic = 'HSESans-SemiBlod.otf'
)
font_add(family = 'Computer Modern',
regular = 'cmunrm.otf')
df1 <- read.csv('ie_daily_04_03_2024.csv')
df1$month <- format(as.Date(df1$date, "%Y-%m-%d"), "%Y-%m")
df1$ie <- df1$ie_new
df1 <- df1[-1]
df1 %>%
filter(month >= '2021-06') %>%
ggplot(aes(x = ie,
y = as.factor(month),
fill = after_stat(x),
)) +
geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01, color = 'white') +
scale_fill_carto_c(palette = 'SunsetDark') +
#scale_fill_viridis_c(name = "%", option = "C") +
theme_ipsum() +
theme(legend.position = 'bottom',
#legend.title = element_text(size=25),
legend.text = element_text(size = 35),
text = element_text(size = 5, color = 'black', family = 'HSE Sans'),
panel.grid.minor.x = element_blank(),
axis.text.x = element_text(size = 35),
axis.text.y = element_text(size = 35),
axis.title.x = element_text(size = 35, family = 'HSE Sans'),
axis.title.y = element_text(size = 35, family = 'HSE Sans'),
plot.title = element_text(family = "HSE Sans",
color = "black",
size = 50,
face = "bold",
hjust = 0.5,
margin = margin(t = 24, b = 6)),
plot.subtitle = element_text(family = "HSE Sans",
color = "black",
size = 41,
face = "plain",
hjust = 0.5,
margin = margin(t = 0, b = 0)),
plot.caption = element_text(family = "HSE Sans",
color = "black",
size = 20,
hjust = 0.5,
margin = margin(t = 0, b = 24))) +
#scale_color_viridis(discrete=TRUE) +
labs(x = 'Функция плотности инфляционных ожиданий', y = 'Месяц')
#title = 'Инфляционные Ожидания в России',
#subtitle = '2021-2022'
ggsave('ie_newest_paper_HSE_Sans_07_12_23.png', dpi = 400, bg = 'white', height = 7, width = 6)
setwd("D:/Работа/Stuff")
read.csv('data_seasonality.csv', sep = ';', dec = ',', header = T)
read.csv('data_seasonality.csv', sep = ';', dec = ',', header = T)
setwd("D:/Работа/Stuff")
read.csv('data_seasonality.csv', sep = ';', dec = ',', header = T)
read.csv('data_seasonality.csv', sep = ';', dec = ',', header = T)
1+1
read.csv('data_seasonality.csv', sep = ';', dec = ',', header = T)
httr::GET('https://github.com/ETymch/Econometrics_2023/raw/main/Datasets/data_seasonality.xlsx')
data_seas <- read_excel('data_seasonality.xlsx') %>%
mutate(Date = as.Date(Date)) %>%
filter(Date >= '2013-01-01')
data_seas %>%
pivot_longer(Prom_M:Trade_M) %>%
ggplot(aes(x = Date, y = value, color = name)) +
geom_line() +
facet_wrap(~name, scales = 'free') +
theme_minimal() +
labs(caption = '100 = 2016 г.')
prom <- data_seas %>%
pull(Prom_M) %>%
ts(c(2013,1), frequency = 12) %>%
log()
trade <- data_seas %>%
pull(Trade_M) %>%
ts(c(2013,1), frequency = 12) %>%
log()
# Праздники upd.
hols <- read.csv('https://raw.githubusercontent.com/ETymch/Econometrics_2023/main/Datasets/russia-holiday-dates.csv', stringsAsFactors = FALSE) %>%
pull(x) %>%
as.Date()
dates <- seq(as.Date('2013-01-01'), as.Date('2024-12-31'), by = 1)
hol_new <- tibble(dates,
hols_ind = ifelse(dates %in% hols, 1, 0)
) %>%
mutate(dates_f = floor_date(dates, 'month')) %>%
group_by(dates_f) %>%
summarize(holidays_share = mean(hols_ind)
) %>%
ungroup() %>%
mutate(yr = floor_date(dates_f, 'year')) %>%
group_by(yr) %>%
mutate(h_sh_yr = sum(holidays_share)) %>%
ungroup() %>%
mutate(count_0 = ifelse(holidays_share == 0, 1, 0)) %>%
group_by(yr) %>%
mutate(nmonth_0 = sum(count_0)) %>%
ungroup() %>%
mutate(holidays_share = ifelse(count_0 == 1, -1 * (h_sh_yr / nmonth_0), holidays_share)) %>%
pull(holidays_share) %>%
ts(start = c(2013,1), frequency = 12)
hol_new
hol_new <- tibble(dates,
hols_ind = ifelse(dates %in% hols, 1, 0)
) %>%
mutate(dates_f = floor_date(dates, 'month')) %>%
group_by(dates_f) %>%
summarize(holidays_share = mean(hols_ind)
) %>%
ungroup() %>%
mutate(x_centered_mean = holidays_share - mean(holidays_share))
hol_new
hol_new <- tibble(dates,
hols_ind = ifelse(dates %in% hols, 1, 0)
) %>%
mutate(dates_f = floor_date(dates, 'month')) %>%
group_by(dates_f) %>%
summarize(holidays_share = mean(hols_ind)
) %>%
ungroup() %>%
mutate(yr = floor_date(dates_f, 'year')) %>%
group_by(yr) %>%
mutate(h_mean_yr = mean(holidays_share)) %>%
ungroup() %>%
mutate(x_centered_mean = holidays_share - h_mean_yr) %>%
pull(x_centered_mean) %>%
ts(start = c(2013,1), frequency = 12)
hol_new
hol_new_0 <- tibble(dates,
hols_ind = ifelse(dates %in% hols, 1, 0)
) %>%
mutate(dates_f = floor_date(dates, 'month')) %>%
group_by(dates_f) %>%
summarize(holidays_share = mean(hols_ind)
) %>%
ungroup() %>%
mutate(yr = floor_date(dates_f, 'year')) %>%
group_by(yr) %>%
mutate(h_sh_yr = sum(holidays_share)) %>%
ungroup() %>%
mutate(count_0 = ifelse(holidays_share == 0, 1, 0)) %>%
group_by(yr) %>%
mutate(nmonth_0 = sum(count_0)) %>%
ungroup() %>%
mutate(holidays_share = ifelse(count_0 == 1, -1 * (h_sh_yr / nmonth_0), holidays_share)) %>%
pull(holidays_share) %>%
ts(start = c(2013,1), frequency = 12)
hol_new_1 <- tibble(dates,
hols_ind = ifelse(dates %in% hols, 1, 0)
) %>%
mutate(dates_f = floor_date(dates, 'month')) %>%
group_by(dates_f) %>%
summarize(holidays_share = mean(hols_ind)
) %>%
ungroup() %>%
mutate(yr = floor_date(dates_f, 'year')) %>%
group_by(yr) %>%
mutate(h_mean_yr = mean(holidays_share)) %>%
ungroup() %>%
mutate(x_centered_mean = holidays_share - h_mean_yr) %>%
pull(x_centered_mean) %>%
ts(start = c(2013,1), frequency = 12)
merge(hol_new_0, hol_new_1, by = 'date')
hol_new_0
hol_new_1
merge(hol_new_0, hol_new_1, by = 'dates')
merge(hol_new_0, hol_new_1, by = c('dates'))
merge(hol_new_0, hol_new_1)
plot(hol_new_0)
setwd("D:/Работа/Project_Forecast_Dashboard/2q2023")
data_mac <- read.csv('data_macro_4q23_1.csv')
out_gap <-
data_mac %>%
pull(Output) %>%
log() %>%
mFilter::hpfilter(freq = 300)
library(tidyverse)
consumption <-
data_mac %>%
pull(Consumption) %>%
log() %>%
mFilter::hpfilter(freq = 300)
consumption <- consumption$cycle %>% diff()
plot(output_gap)
plot(out_gap)
lines(consumption)
tibble(index = seq(1, length(out_gap)),
out_gap,
consumption) %>%
pivot_linger(out_gap:consumption) %>%
ggplot(aes(x = index, y = value, color = name)) +
geom_line()
tibble(index = seq(1, length(out_gap)),
out_gap,
consumption) %>%
pivot_longer(out_gap:consumption) %>%
ggplot(aes(x = index, y = value, color = name)) +
geom_line()
data_mac %>%
pull(Consumption) %>%
log() %>%
diff() %>%
plot()
lines(consumption)
library(tidyverse)
data_mac <- read.csv('data_macro_4q23_1.csv')
out_gap <-
data_mac %>%
pull(Output) %>%
log() %>%
mFilter::hpfilter(freq = 300)
out_gap <- out_gap$cycle %>% diff()
consumption <-
data_mac %>%
pull(Consumption) %>%
log() %>%
mFilter::hpfilter(freq = 300)
consumption <- consumption$cycle %>% diff()
#tibble(index = seq(1, length(out_gap)),
#       out_gap,
#       consumption) %>%
#  pivot_longer(out_gap:consumption) %>%
#  ggplot(aes(x = index, y = value, color = name)) +
#  geom_line()
df_mac <-
data_frame(date = seq(from = as.Date("2014-10-01"), length.out = 37, by = 'quarter'),
Output_Gap = out_gap,
Consumption_Gap = consumption,
CPI = data_mac$CPI %>% log() %>% diff,
IE = data_mac$Inf_Exp %>% log() %>% diff
)
write.csv(df_mac, 'mswm_data_ru.csv')
seq(from = as.Date("2014-07-01"), length.out = 38, by = 'quarter')
blogdown:::preview_site()
