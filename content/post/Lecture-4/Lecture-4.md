---
title: "Лекция 4"
author: "Е. Тымченко"
date: 2023-06-27
categories: ["R"]
tags: ["Econ"]
---

# Метод максимального правдоподобия

Чтобы лучше усвоить, в чём состоит метод максимального правдоподобия и чем он отличается от МНК, давайте вспомним, в чём состоял последний.

<center>

![yay](https://raw.githubusercontent.com/ETymch/Econometrics_2023/main/Pics/yay_statistics.gif)

</center>

Метод наименьших квадратов предполагает, что у нас есть модель, где `\(X\)` - табличка с независимыми переменными, `\(\beta\)` - набор коэффициентов, с коротыми независимые переменные влияют на `\(y\)`, `\(\epsilon\)` - все незначительные факторы, которые, как мы ожидаем, в сумме дают 0 и не зависят от `\(X\)`.

`$$y = X\beta + \epsilon$$`
`\(y\)` и `\(X\)` мы уже знаем, поскольку, данные у нас есть. Остаётся найти `\(\beta\)`, решив задачу минимизации квадратов ошибок в нашей модели:

`$$\min_{\hat{\beta}} [y - X\hat{\beta}]^2$$`
После взятия производной и пары алгебраических преобразований мы получили оценку для `\(\hat{\beta}\)`

`$$\hat{\beta} = (X'X)^{-1}X'Y$$`
И замечательное свойство этой оценки - **несмещённость**.

`$$\epsilon \sim \mathbb{N}(0,\sigma)$$`

В тот раз мы не делали никаких предположений о том, как распределён `\(y\)`. Всё, что мы сделали - это провели такую линию, чтобы сумма квадратов ошибок в выборке была минимальной. 

* Предположение в модели, оценённой методом наименьших квадратов: `\(y \in (-\infty, \infty)\)`.
* Предположение в модели, оценённой методом максимального правдоподобия: `\(у\)` имеет какое-то распределение (зависит от модели) и определена на заданном интервале. Например, биномиальное распределение (например, подбрасывание монетки), где `\(y \in \{0, 1\}\)`.

Это более общий и гибкий способ моделирования. Более того, мы явно указываем в модели свои предположения о том, как распределены данные.

Процедура, с помощью которой мы получаем коэффициенты, тоже отличается.

Давайте построим статистическую модель:

* условная вероятность того, что человек болен диабетом при заданном уровне глюкозы в крови равна `\(P(y = y_i | x)\)`, `\(P(y = y_i | x) \in [0, 1]\)`
* тогда вероятность, что человек здоров, равна `\(1 - P(y = y_i | x)\)`.
* Мы хотим смоделировать вероятность `\(P\)`. Придумаем функцию, которая имела бы область определения `\((0,1)\)` и зависела от параметров `\(\beta\)`, которые принимают значения от `\(-\infty\)` до `\(+\infty\)`
* Такая функция известна - сигмоид.

`$$P(y = y_i) = \frac{1}{1 + e^{-X\beta}}$$`
Число в знаменателе, `\(e^{-X\beta}\)` принимает значения от 0 до бесконечности. Так, если `\(e^{-X\beta} = \infty\)`, искомая вероятность равна 0. Если же `\(e^{-X\beta} = 0\)`, то искомая вероятность равна 1.

Наша идея в том, чтобы подобрать такие коэффициенты `\(\beta\)` в уравнении, чтобы вероятность `\(P\)`  **с наибольшим правдоподобием** происходила из биномиального распределения (распределения, в котором исходы принимают значения 0 или 1).

> Как получить эти коэффициенты?

Максимизировать логистическую функцию по `\(\beta\)`.

Иначе говоря, взять частные производные по каждой `\(\beta\)`, приравнять к 0, решить систему уравнений.

> Почему метод называют методом максимального правдоподобия?

> Какие ещё предположения можно делать о распределении y?
